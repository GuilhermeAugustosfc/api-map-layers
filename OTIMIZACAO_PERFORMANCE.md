# Otimiza√ß√£o e Performance - HERE Proxy API

## Vis√£o Geral

Este documento detalha as recomenda√ß√µes e pr√≥ximos passos para otimizar a performance, escalabilidade e observabilidade da API de proxy do HERE Maps.

## Estado Atual (Bom)

- ‚úÖ **Async com httpx**: Pool de conex√µes e keep-alive configurados
- ‚úÖ **Cache em mem√≥ria**: TTL por tile e por √≠ndice
- ‚úÖ **M√©tricas**: Contadores de hits/misses/upstream por √≠ndice
- ‚úÖ **CORS**: Configurado para frontend
- ‚úÖ **Docker**: Configura√ß√£o b√°sica funcional

## Plano de Otimiza√ß√µes

### 1. Streaming de Respostas (Lat√™ncia/Mem√≥ria)

**Objetivo**: Reduzir TTFB e pico de mem√≥ria

**Implementa√ß√£o**:

```python
# Usar StreamingResponse com httpx.stream()
async def here_proxy_streaming(path: str, request: Request):
    # ... l√≥gica de cache ...

    if cached:
        return StreamingResponse(
            iter([content_bytes]),
            media_type=content_type,
            headers={"X-Cache": "HIT", "X-Index": indice}
        )

    # Para upstream
    async with client.stream("GET", here_url, params=params_items) as resp:
        return StreamingResponse(
            resp.aiter_bytes(),
            media_type=resp.headers.get("content-type", "image/png"),
            headers={"X-Cache": "MISS", "X-Index": indice}
        )
```

**Benef√≠cios**:

- Menor TTFB (Time To First Byte)
- Menor pico de mem√≥ria em tiles grandes
- Melhor experi√™ncia do usu√°rio

### 2. HTTP/2 no Upstream (Paralelismo)

**Objetivo**: Habilitar multiplexa√ß√£o para melhor performance

**Implementa√ß√£o**:

```bash
# Instalar suporte HTTP/2
pip install "httpx[http2]"
```

```python
# Ativar no cliente
app.state.http_client = httpx.AsyncClient(
    http2=True,  # Habilitar HTTP/2
    timeout=httpx.Timeout(10.0, read=30.0, connect=5.0),
    limits=httpx.Limits(max_connections=200, max_keepalive_connections=100),
)
```

**Benef√≠cios**:

- Multiplexa√ß√£o de conex√µes
- Redu√ß√£o de lat√™ncia m√©dia em alto RPS
- Melhor utiliza√ß√£o de banda

### 3. Servidor Mais R√°pido (Uvicorn Standard)

**Objetivo**: Otimizar o servidor ASGI

**Implementa√ß√£o**:

```bash
# Instalar uvicorn com otimiza√ß√µes
pip install "uvicorn[standard]"
```

```bash
# Executar com otimiza√ß√µes
uvicorn main:app --host 0.0.0.0 --port 8000 \
  --http httptools \
  --loop uvloop \
  --workers 2
```

**Benef√≠cios**:

- httptools: Parser HTTP mais r√°pido
- uvloop: Loop de eventos otimizado
- Workers: Paralelismo de processos

### 4. Cache com Limites (Evic√ß√£o/LRU)

**Objetivo**: Evitar crescimento indefinido de mem√≥ria

**Op√ß√£o A - In-Memory LRU**:

```python
from cachetools import LRUCache

# Substituir dict por LRU
tile_cache = LRUCache(maxsize=50000)  # 50k entradas m√°ximas
```

**Op√ß√£o B - Redis (Recomendado para multi-worker)**:

```python
import redis.asyncio as redis

# Cliente Redis
redis_client = redis.Redis(host='localhost', port=6379, db=0)

# Cache com TTL
async def get_cached_tile(cache_key: str):
    return await redis_client.get(cache_key)

async def set_cached_tile(cache_key: str, content: bytes, ttl: int):
    await redis_client.setex(cache_key, ttl, content)
```

**Benef√≠cios**:

- Controle de mem√≥ria
- Cache compartilhado entre workers
- Lat√™ncia est√°vel em alto tr√°fego

### 5. Redu√ß√£o de Conten√ß√£o de Locks

**Objetivo**: Otimizar para alto RPS

**Implementa√ß√£o**:

```python
# Fast-path sem lock para leitura
async def get_cached_tile_fast(cache_key: str):
    # Leitura sem lock (thread-safe para dict em Python)
    cached = tile_cache.get(cache_key)
    if cached and cached[2] > time.time():
        return cached
    return None

# Lock apenas para escrita
async def set_cached_tile_safe(cache_key: str, content: bytes, ttl: int):
    async with cache_lock:
        tile_cache[cache_key] = (content, content_type, time.time() + ttl)
```

**Benef√≠cios**:

- Menor lat√™ncia em hits
- Melhor throughput
- Menos conten√ß√£o

### 6. Observabilidade Avan√ßada

**Objetivo**: M√©tricas e logs estruturados

**Prometheus/Grafana**:

```yaml
# prometheus.yml
scrape_configs:
  - job_name: "here-proxy"
    static_configs:
      - targets: ["localhost:8000"]
    metrics_path: "/metrics/prometheus"
```

**Dashboards Sugeridos**:

- Hit ratio por √≠ndice
- Upstream calls vs cache hits
- Lat√™ncia p50/p95/p99
- Erros por √≠ndice

**Logs Estruturados**:

```python
import logging
import json

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def log_request(path: str, indice: str, cache_status: str, status: int, latency: float):
    logger.info(json.dumps({
        "method": "GET",
        "path": path,
        "indice": indice,
        "cache_status": cache_status,
        "status": status,
        "latency_ms": round(latency * 1000, 2),
        "timestamp": time.time()
    }))
```

### 7. Resili√™ncia (Upstream HERE)

**Objetivo**: Lidar com falhas do HERE

**Implementa√ß√£o**:

```python
import tenacity

@tenacity.retry(
    stop=tenacity.stop_after_attempt(3),
    wait=tenacity.wait_exponential(multiplier=1, min=4, max=10),
    retry=tenacity.retry_if_exception_type((httpx.TimeoutException, httpx.ConnectError))
)
async def fetch_from_here_with_retry(client, url, params):
    return await client.get(url, params=params)
```

**Benef√≠cios**:

- Retry autom√°tico para falhas transit√≥rias
- Backoff exponencial
- Melhor disponibilidade

### 8. CDN/Proxy na Frente

**Objetivo**: Cache externo adicional

**Cloudflare**:

- Cache por query (inclui √≠ndice)
- Respeitar Cache-Control
- DDoS protection

**NGINX**:

```nginx
proxy_cache_path /tmp/nginx_cache levels=1:2 keys_zone=here_cache:10m max_size=10g inactive=60m;

location /here-proxy/ {
    proxy_cache here_cache;
    proxy_cache_key "$request_uri";
    proxy_cache_valid 200 1h;
    proxy_pass http://backend:8000;
}
```

### 9. Seguran√ßa e Rate Limiting

**Objetivo**: Proteger contra abuso

**Rate Limiting por √çndice**:

```python
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address

limiter = Limiter(key_func=get_remote_address)
app.state.limiter = limiter

@app.get("/here-proxy/{path:path}")
@limiter.limit("100/minute")  # 100 requests por minuto por IP
async def here_proxy(path: str, request: Request):
    # ... implementa√ß√£o ...
```

**API Key no Servidor**:

```python
import os

HERE_API_KEY = os.getenv("HERE_API_KEY")

# Remover apiKey do request e usar a do servidor
params_items = [
    (k, v) for (k, v) in request.query_params.multi_items()
    if k not in ["indice", "apiKey"]
]
params_items.append(("apiKey", HERE_API_KEY))
```

### 10. Escala Horizontal

**Objetivo**: Suportar m√∫ltiplos workers/containers

**Docker Compose com Redis**:

```yaml
version: "3.8"
services:
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"

  here-proxy:
    build: .
    ports:
      - "8000:8000"
    environment:
      - REDIS_URL=redis://redis:6379
    depends_on:
      - redis
    deploy:
      replicas: 3
```

**Kubernetes HPA**:

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: here-proxy-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: here-proxy
  minReplicas: 2
  maxReplicas: 10
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 70
```

## Roteiro de Implementa√ß√£o

### Fase 1 - Otimiza√ß√µes B√°sicas (1-2 semanas)

1. ‚úÖ Uvicorn standard + ajustar healthcheck do Docker
2. üîÑ LRU no cache in-memory (maxsize) ou Redis
3. üîÑ Streaming de respostas
4. üîÑ HTTP/2 no httpx

### Fase 2 - Observabilidade (1 semana)

1. üîÑ Logs estruturados
2. üîÑ Dashboards Grafana
3. üîÑ M√©tricas avan√ßadas

### Fase 3 - Produ√ß√£o (1-2 semanas)

1. üîÑ Rate limiting por √≠ndice
2. üîÑ CDN/NGINX opcional
3. üîÑ Resili√™ncia e retry
4. üîÑ Escala horizontal

### Fase 4 - Monitoramento (Cont√≠nuo)

1. üîÑ Alertas baseados em m√©tricas
2. üîÑ SLOs/SLIs definidos
3. üîÑ Otimiza√ß√µes baseadas em dados reais

## M√©tricas de Sucesso

### Performance

- **Lat√™ncia**: p95 < 200ms para cache hits
- **Throughput**: 1000+ RPS por worker
- **Hit Ratio**: > 80% em produ√ß√£o

### Recursos

- **CPU**: < 70% m√©dia
- **Mem√≥ria**: < 2GB por container
- **Rede**: < 100MB/s upstream

### Disponibilidade

- **Uptime**: > 99.9%
- **Erros**: < 0.1% upstream errors
- **Cache**: Hit ratio est√°vel

## Ferramentas de Benchmark

### K6 (Teste de Carga)

```javascript
import http from "k6/http";
import { check } from "k6";

export const options = {
  stages: [
    { duration: "2m", target: 100 }, // Ramp up
    { duration: "5m", target: 100 }, // Stay
    { duration: "2m", target: 0 }, // Ramp down
  ],
};

export default function () {
  const url =
    "http://localhost:8000/here-proxy/mc/5/15/13/png?indice=123&size=512&apiKey=test&style=explore.day&lang=en";

  const response = http.get(url);

  check(response, {
    "status is 200": (r) => r.status === 200,
    "response time < 200ms": (r) => r.timings.duration < 200,
    "cache header present": (r) => r.headers["X-Cache"] !== undefined,
  });
}
```

### wrk (Teste Simples)

```bash
# Teste b√°sico
wrk -t12 -c400 -d30s http://localhost:8000/here-proxy/mc/5/15/13/png?indice=123&size=512

# Teste com Lua para variar √≠ndices
wrk -t12 -c400 -d30s -s test.lua http://localhost:8000/here-proxy/mc/5/15/13/png
```

## Riscos e Aten√ß√µes

### Riscos T√©cnicos

- **Multi-worker sem cache compartilhado**: Reduz hit ratio
- **Streaming**: Aumenta conex√µes abertas; monitore limites do SO
- **HTTP/2**: Requer `h2`; teste bem antes de ativar em produ√ß√£o

### Riscos de Neg√≥cio

- **Custo HERE**: Monitorar uso para evitar surpresas
- **SLA**: Definir expectativas claras com stakeholders
- **Cache invalidation**: Estrat√©gia para atualiza√ß√µes de tiles

## Checklist de Configura√ß√£o

### Vari√°veis de Ambiente

```bash
# Obrigat√≥rias
HERE_API_KEY=your_api_key_here

# Opcionais
CACHE_MAXSIZE=50000
CACHE_TTL_CAP=3600
REDIS_URL=redis://localhost:6379
LOG_LEVEL=INFO
```

### Recursos do Sistema

```bash
# Aumentar limites do SO
ulimit -n 65536  # File descriptors
sysctl -w net.core.somaxconn=65535  # TCP backlog
```

### Monitoramento

- [ ] Prometheus configurado
- [ ] Grafana dashboards criados
- [ ] Alertas configurados
- [ ] Logs centralizados
- [ ] M√©tricas de neg√≥cio definidas

## Conclus√£o

Este roteiro de otimiza√ß√£o visa transformar a API de proxy do HERE em uma solu√ß√£o de produ√ß√£o robusta, escal√°vel e observ√°vel. As implementa√ß√µes devem ser feitas incrementalmente, sempre medindo o impacto antes e depois de cada mudan√ßa.

**Prioridade**: Foque primeiro nas otimiza√ß√µes que trazem maior impacto (cache LRU, streaming, HTTP/2) e depois evolua para recursos mais avan√ßados conforme a necessidade do neg√≥cio.
